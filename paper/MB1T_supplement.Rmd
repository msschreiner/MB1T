---
title             : "Manybabies1 Test-Retest Supplementary Information"
shorttitle        : "MB1T supplementary"

figsintext        : yes
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

bibliography      : ["r-references.bib"]

documentclass     : "apa6"
classoption       : "man, donotrepeattitle"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library(papaja)
library(dplyr)
library(tidyr)
library(readxl)
library(lme4)
library(readr)
library(langcog)
library(ggthemes)
library(tidyverse)
library(here)
library(knitr)
library(kableExtra)
library("langcog")
library(lmerTest)
library(ggplot2)
library(cowplot)
library(tidymodels)

read_path <- here("data","processed")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed,echo = FALSE, warning = FALSE, message = FALSE)
```

## S1: Relationship between the number of trials infants contribute in each session

```{r}
# importing dataset (after excluding session and trial errors)
df_all <- read_csv(here(read_path,"df_all_after_exclusions.csv"))

#some minor data cleaning
#not cleaning based on minimum number of trials in order to see even infants contributing at least one trial
df_all <- df_all %>%
  filter(Condition != "training") %>%
  filter(LT >= 2) # minimum LT for inclusion

# calculate number of trials that each participant contributes per session
df_all_trials <- df_all %>%
  group_by(Subject_Unique,Session, Method) %>%
  summarise(N_trials = length(trial_num)) %>%
  mutate(
    N_trials = as.numeric(N_trials), #probably not needed, just to be safe
    Method = as.factor(Method)) %>%
  mutate(
    Session = case_when(
      Session==1 ~ "Test",
      Session==2 ~ "Retest"
    )
  )

df_all_trials <- df_all_trials %>% 
  pivot_wider(names_from = Session,values_from = N_trials)

#compute correlation
cor_trials <- cor.test(df_all_trials$Test,df_all_trials$Retest)
cor_trials_out <- apa_print(cor_trials)
```

```{r sfig1, fig.cap = "Correlation between the number of trials contributed in session 1 and session 2. Each data point represents one infant. Colored lines represent linear fits for each method."}
# jittering individual data points in order to make overlapping data points visible
trials <- ggplot(df_all_trials, aes(x=Test, y=Retest))+
  geom_jitter(width=0.5,height=0.5,aes(colour = Method),alpha=0.5)+
  geom_smooth(aes(colour = Method,group=Method),method=lm, se=FALSE,alpha=0.3)+
  geom_smooth(method=lm, colour= "black")+
  scale_x_continuous(seq(0,16,2),name="Number of Trials During Session 1")+
  scale_y_continuous(seq(0,16,2),name="Number of Trials During Session 2")+
  theme_cowplot()+
  theme(legend.position=c(0.02,0.8))
#plot
trials
```

Are there stable individual differences in how likely an infant is to contribute a high number of trials?
To answer this question, we conducted an exploratory analysis investigating whether there is a relationship between the number of trials an infant contributed in session 1 and session 2. 
Do infants who contribute a higher number of trials during their first testing session also tend to contribute more trials during their second testing session? 
A positive correlation between trial numbers during the first and second session would indicate that their is some stability in a given infants' likelihood of remaining attentive throughout the experiment.
On the other hand, the absence of a correlation would indicate that the number of trials a given infant contributes is not predictive of how many trials they might contribute during their next session.

We found a strong positive correlation between number of trials contributed during the first and the second session `r cor_trials_out$full_result` (see Figure 1). 
This result suggests that if infants contribute a higher number of trials in one session, compared to other infants, they are likely to contribute a higher number of trials in their next session.
This finding is consistent with the hypothesis that how attentive infants are throughout an experiment (and hence how many trials they contribute) is a stable individual difference, at least for some infant looking time tasks.
Researchers should therefore be mindful of the fact that decisions about including or excluding infants based on trials contributed may selectively sample a specific sub-set of the infant population they are studying [@debolt2020robust;@byers2021six].

## S2: Patterns of preference across sessions
```{r,message=FALSE,warning=FALSE}

#read in cleaned and aggregated data
data_clean <- read_csv(here(read_path,"clean_data_minimum_trials_per_type_1.csv"))
agg_subjects <- read_csv(here(read_path,"all_agg_subjects_paired_minimum_trials_per_type_1.csv"))
all_agg_subjects_paired <- read_csv(here(read_path,"all_agg_subjects_paired_minimum_trials_per_type_1.csv")) 
all_agg_subjects_paired_retest <- read_csv(here(read_path,"all_agg_subjects_paired_retest_minimum_trials_per_type_1.csv")) %>%
  mutate(Pref_Test=case_when(
             Diff_1 > 0 ~ "IDS_preference",
             Diff_1 < 0 ~ "ADS_preference",
             Diff_1 == 0 ~ "no_preference"
             ),
         Pref_Retest=case_when(
             Diff_2 > 0 ~ "IDS_preference",
             Diff_2 < 0 ~ "ADS_preference",
             Diff_2 == 0 ~ "no_preference"
             )) %>%
  mutate(reversal_binary = case_when((Pref_Test == "IDS_preference" & Pref_Retest == "IDS_preference")  ~ 0,
                              (Pref_Test == "ADS_preference" & Pref_Retest == "ADS_preference")  ~ 0,
                              (Pref_Test == "IDS_preference" & Pref_Retest == "ADS_preference")  ~ 1,
                              (Pref_Test == "ADS_preference" & Pref_Retest == "IDS_preference")  ~ 1)) %>%
  unite(reversal_type,Pref_Test,Pref_Retest,remove=FALSE) %>%
  mutate(reversal_type=str_remove_all(reversal_type,pattern="_preference"))

#overall percent reversals
reversal_tally <- all_agg_subjects_paired_retest %>%
  ungroup() %>%
  group_by(reversal_type) %>%
  tally()
total_consistent <- sum(filter(reversal_tally, reversal_type %in% c("IDS_IDS","ADS_ADS"))$n)
total_n <- sum(reversal_tally$n)
percent_consistent <- total_consistent/total_n 
```

We also conducted analyses to explore whether there were any patterns of preference reversal across test sessions.
While there was no strong correlation in the magnitude of IDS preference between test session 1 and test session 2, here we asked whether infants consistently expressed the same preference across test sessions.
Overall, `r round(percent_consistent,3)*100 `% of the infants had a consistent preference from test to retest session, indicating that infants were not more likely than chance to maintain their preference from test session 1 to test session 2 (exact binomial test; *p* = 
`r round(binom.test(total_consistent,total_n)$p.value,2)`).
Of the `r sum(reversal_tally$n)` total infants, `r round(filter(reversal_tally,reversal_type=="IDS_IDS")$n/sum(reversal_tally$n),3)*100`% of infants showed a consistent infant-directed speech preference and `r round(filter(reversal_tally,reversal_type=="ADS_ADS")$n/sum(reversal_tally$n),3)*100`% showed a consistent adult-directed speech preference.
`r round(filter(reversal_tally,reversal_type=="IDS_ADS")$n/sum(reversal_tally$n),3)*100`% of infants switched from an infant-directed speech preference at test session 1 to an adult-directed speech preference at test session 2 and `r round(filter(reversal_tally,reversal_type=="ADS_IDS")$n/sum(reversal_tally$n),3)*100`% switched from an adult-directed speech preference to an infant-directed speech preference. 


Next, we explored whether we could detect any systematic clustering of infants with distinct patterns of preference across the test and retest session.
We took a bottom-up approach and conducted a *k*-means clustering of the test-retest difference data.
We found little evidence of distinct clusters emerging from these groupings: the clusterings ranging from *k*=2 (2 clusters) to *k*=4 (4 clusters) appear to simply track  whether participants are approximately above or below the mean looking time difference for test session 1 and test session 2, and the diagnostic elbow plot shows little evidence of a qualitative improvement as the number of clusters is increased.

```{r}
d <- all_agg_subjects_paired_retest %>% 
  column_to_rownames(var = "Subject_Unique") %>% 
  filter(!is.na(Diff_1)) %>%
  ungroup() %>% 
  select(Diff_1,Diff_2)

kclusts <- 
  tibble(k = 1:9) %>%
  mutate(
    kclust = map(k, ~kmeans(d, .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, d)
  )

clusters <- 
  kclusts %>%
  unnest(cols = c(tidied))

assignments <- 
  kclusts %>% 
  unnest(cols = c(augmented)) %>%
  mutate(
    mean_diff_1=mean(Diff_1),
    mean_diff_2=mean(Diff_2),
  )

clusterings <- 
  kclusts %>%
  unnest(cols = c(glanced))
```

```{r fig2, fig.cap = " (A) Results from the k-means clustering analysis of IDS preference in session 1 and 2 for different numbers of k  and (B) the corresponding elbow plot of the total within-cluster sum of squares. In (A), points represent indvidual participants' magnitude of looking time difference at test sessions 1 (x-axis) and 2 (y-axis). The solid line indicates no preference for IDS vs. ADS, the dotted lines indicate mean IDS preference at test session 1 and 2, respectively. Colors indicate clusters from the k-means clustering for different values of k."}
p1 <- 
  ggplot(assignments, aes(x = Diff_1, y = Diff_2)) +
  geom_point(aes(color = .cluster), alpha = 0.8) + 
  facet_wrap(~ k)+
  geom_hline(yintercept=0)+
  geom_vline(xintercept=0)+
  geom_hline(yintercept=assignments$mean_diff_2[1],linetype="dotted")+
  geom_vline(xintercept=assignments$mean_diff_1[1],linetype="dotted")+
  xlab("IDS preference in first session")+
  ylab("IDS preference in second session")

p2 <- ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point()+
  xlab("Number of clusters")+
  scale_x_continuous(breaks=seq(1,10))+
  ylab("Total within-cluster sum of squares")

plot_grid(p1,p2,labels=c("A","B"),rel_widths=c(2,1))
```


## S3: Deviations from the preregistration

Below, we document all deviations from the preregistered methods and analyses [https://osf.io/v5f8t](https://osf.io/v5f8t).

- All infants with usable data for both test and retest session were included in the analyses, regardless of the number of total of infants a lab was able to contribute after exclusion. This decision is consistent with past decisions in ManyBabies projects to be as inclusive about data inclusion as possible [@manybabies2020quantifying].
- A small number of infants with a time between sessions above 31 days were also included in the analyses (n=2).
- Consistent with analytic decisions in ManyBabies 1 [@manybabies2020quantifying], total looking times were truncated at 18 seconds (the maximum trial time) in the small number of cases where recorded looking times were slightly greater than 18s (presumably due to small measurement error in recording infant looking times).


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
